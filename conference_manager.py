#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼šè®®æ•°æ®ç®¡ç†å™¨ - ç®¡ç†ä¼šè®®æ•°æ®çš„åŠ è½½ã€ä¿å­˜ã€åˆå¹¶å’Œè¿ç§»
æ”¯æŒå‘åå…¼å®¹å’Œæ•°æ®ç‰ˆæœ¬æ§åˆ¶
"""

import json
import os
import re
import sys
import shutil
from datetime import datetime, timedelta
from typing import List, Dict, Optional

# Windowsæ§åˆ¶å°ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import codecs
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)


class ConferenceManager:
    """ä¼šè®®æ•°æ®ç®¡ç†å™¨"""

    def __init__(self, data_file: str = 'conferences.json'):
        """åˆå§‹åŒ–ä¼šè®®ç®¡ç†å™¨

        Args:
            data_file: ä¼šè®®æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.data_file = data_file
        self.backup_dir = 'backups'
        self.conferences = []
        self.metadata = {
            'version': '2.0',
            'last_updated': None,
            'total_count': 0
        }

        # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
        os.makedirs(self.backup_dir, exist_ok=True)

        # åŠ è½½æ•°æ®
        self.load_data()

    def load_data(self) -> List[Dict]:
        """åŠ è½½ä¼šè®®æ•°æ®ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰

        Returns:
            ä¼šè®®æ•°æ®åˆ—è¡¨
        """
        if not os.path.exists(self.data_file):
            print(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_file}")
            self.conferences = []
            return self.conferences

        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ ¼å¼
            if isinstance(data, dict) and 'conferences' in data:
                # æ–°æ ¼å¼ï¼šåŒ…å« metadata
                self.conferences = data['conferences']
                self.metadata = data.get('metadata', {})
            elif isinstance(data, list):
                # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯ä¼šè®®åˆ—è¡¨
                self.conferences = data
                # è¿ç§»åˆ°æ–°æ ¼å¼
                self.conferences = [self.migrate_old_format(conf) for conf in self.conferences]
            else:
                print(f"âŒ æœªçŸ¥çš„æ•°æ®æ ¼å¼")
                self.conferences = []

            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.conferences)} ä¸ªä¼šè®®")
            return self.conferences

        except json.JSONDecodeError as e:
            print(f"âŒ æ•°æ®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            self.conferences = []
            return self.conferences

    def save_data(self, create_backup: bool = True) -> bool:
        """ä¿å­˜ä¼šè®®æ•°æ®

        Args:
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½

        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆ›å»ºå¤‡ä»½
            if create_backup and os.path.exists(self.data_file):
                self._create_backup()

            # æ›´æ–°å…ƒæ•°æ®
            self.metadata['last_updated'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            self.metadata['total_count'] = len(self.conferences)

            # ä¿å­˜æ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰
            data = {
                'conferences': self.conferences,
                'metadata': self.metadata
            }

            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {self.data_file}")
            print(f"   æ€»è®¡: {len(self.conferences)} ä¸ªä¼šè®®")
            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False

    def add_conference(self, conference: Dict, source_id: str = 'manual') -> bool:
        """æ·»åŠ å•ä¸ªä¼šè®®

        Args:
            conference: ä¼šè®®æ•°æ®
            source_id: æ•°æ®æºID

        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            # ç”ŸæˆIDï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
            if 'id' not in conference:
                conference['id'] = self._generate_conf_id(conference)

            # æ·»åŠ éªŒè¯ä¿¡æ¯
            if 'verification' not in conference:
                conference['verification'] = {
                    'status': 'unverified',
                    'sources': [{
                        'source_id': source_id,
                        'last_checked': datetime.now().strftime('%Y-%m-%d'),
                        'data': {k: v for k, v in conference.items()
                                if k not in ['verification', 'metadata']}
                    }],
                    'conflicts': [],
                    'confidence': 0.5
                }

            # æ·»åŠ å…ƒæ•°æ®
            if 'metadata' not in conference:
                conference['metadata'] = {
                    'created_at': datetime.now().strftime('%Y-%m-%d'),
                    'updated_at': datetime.now().strftime('%Y-%m-%d'),
                    'updated_by': source_id
                }

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = self.find_conference(conference['id'])
            if existing:
                print(f"âš ï¸  ä¼šè®®å·²å­˜åœ¨: {conference['name']}")
                return False

            self.conferences.append(conference)
            print(f"âœ… å·²æ·»åŠ ä¼šè®®: {conference['name']}")
            return True

        except Exception as e:
            print(f"âŒ æ·»åŠ ä¼šè®®å¤±è´¥: {e}")
            return False

    def update_conference(self, conf_id: str, update_data: Dict,
                         source_id: str = 'manual') -> bool:
        """æ›´æ–°ä¼šè®®ä¿¡æ¯

        Args:
            conf_id: ä¼šè®®ID
            update_data: è¦æ›´æ–°çš„æ•°æ®
            source_id: æ•°æ®æºID

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            conf = self.find_conference(conf_id)
            if not conf:
                print(f"âŒ æœªæ‰¾åˆ°ä¼šè®®: {conf_id}")
                return False

            # æ›´æ–°å­—æ®µ
            for key, value in update_data.items():
                if value is not None:  # åªæ›´æ–°éç©ºå€¼
                    conf[key] = value

            # æ›´æ–°å…ƒæ•°æ®
            if 'metadata' in conf:
                conf['metadata']['updated_at'] = datetime.now().strftime('%Y-%m-%d')
                conf['metadata']['updated_by'] = source_id

            print(f"âœ… å·²æ›´æ–°ä¼šè®®: {conf.get('name', conf_id)}")
            return True

        except Exception as e:
            print(f"âŒ æ›´æ–°ä¼šè®®å¤±è´¥: {e}")
            return False

    def delete_conference(self, conf_id: str) -> bool:
        """åˆ é™¤ä¼šè®®

        Args:
            conf_id: ä¼šè®®ID

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            conf = self.find_conference(conf_id)
            if not conf:
                print(f"âŒ æœªæ‰¾åˆ°ä¼šè®®: {conf_id}")
                return False

            self.conferences.remove(conf)
            print(f"âœ… å·²åˆ é™¤ä¼šè®®: {conf.get('name', conf_id)}")
            return True

        except Exception as e:
            print(f"âŒ åˆ é™¤ä¼šè®®å¤±è´¥: {e}")
            return False

    def find_conference(self, conf_id: str) -> Optional[Dict]:
        """æŸ¥æ‰¾ä¼šè®®

        Args:
            conf_id: ä¼šè®®ID

        Returns:
            ä¼šè®®æ•°æ®ï¼ˆæœªæ‰¾åˆ°è¿”å›Noneï¼‰
        """
        for conf in self.conferences:
            if conf.get('id') == conf_id:
                return conf
        return None

    def merge_data(self, new_data: List[Dict], source_id: str = 'merged',
                   update_existing: bool = True) -> Dict:
        """åˆå¹¶æ–°æ•°æ®

        Args:
            new_data: æ–°ä¼šè®®æ•°æ®åˆ—è¡¨
            source_id: æ•°æ®æºID
            update_existing: æ˜¯å¦æ›´æ–°å·²å­˜åœ¨çš„ä¼šè®®

        Returns:
            åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            'added': 0,
            'updated': 0,
            'skipped': 0,
            'errors': 0
        }

        for new_conf in new_data:
            try:
                # ç”ŸæˆID
                conf_id = new_conf.get('id') or self._generate_conf_id(new_conf)

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = self.find_conference(conf_id)

                if existing:
                    if update_existing:
                        # æ›´æ–°å·²å­˜åœ¨çš„ä¼šè®®
                        self.update_conference(conf_id, new_conf, source_id)
                        stats['updated'] += 1
                    else:
                        stats['skipped'] += 1
                else:
                    # æ·»åŠ æ–°ä¼šè®®
                    self.add_conference(new_conf, source_id)
                    stats['added'] += 1

            except Exception as e:
                print(f"âŒ åˆå¹¶ä¼šè®®å¤±è´¥: {e}")
                stats['errors'] += 1

        return stats

    def migrate_old_format(self, old_conf: Dict) -> Dict:
        """è¿ç§»æ—§æ ¼å¼æ•°æ®åˆ°æ–°æ ¼å¼

        Args:
            old_conf: æ—§æ ¼å¼ä¼šè®®æ•°æ®

        Returns:
            æ–°æ ¼å¼ä¼šè®®æ•°æ®
        """
        # å¦‚æœå·²ç»æ˜¯æ–°æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if 'verification' in old_conf and 'metadata' in old_conf:
            return old_conf

        # ç”ŸæˆID
        conf_id = self._generate_conf_id(old_conf)

        # è¿ç§»åˆ°æ–°æ ¼å¼
        new_conf = {
            'id': conf_id,
            'name': old_conf.get('name', ''),
            'rank': old_conf.get('rank', 'N/A'),
            'deadline': old_conf.get('deadline', ''),
            'conference_date': old_conf.get('conference_date', ''),
            'website': old_conf.get('website', ''),
            'description': old_conf.get('description', ''),
            'type': old_conf.get('type', 'conference'),
            'fields': old_conf.get('fields', []),
            'verification': {
                'status': 'unverified',
                'sources': [{
                    'source_id': 'legacy',
                    'last_checked': datetime.now().strftime('%Y-%m-%d'),
                    'data': {
                        'name': old_conf.get('name'),
                        'deadline': old_conf.get('deadline'),
                        'rank': old_conf.get('rank')
                    }
                }],
                'conflicts': [],
                'confidence': 0.5
            },
            'metadata': {
                'created_at': old_conf.get('created_at', datetime.now().strftime('%Y-%m-%d')),
                'updated_at': datetime.now().strftime('%Y-%m-%d'),
                'updated_by': 'migration'
            }
        }

        return new_conf

    def filter_conferences(self, **filters) -> List[Dict]:
        """ç­›é€‰ä¼šè®®

        Args:
            **filters: ç­›é€‰æ¡ä»¶
                - rank: CCFç­‰çº§ï¼ˆA/B/Cï¼‰
                - field: ç ”ç©¶é¢†åŸŸ
                - type: ç±»å‹ï¼ˆconference/journalï¼‰
                - days_after: æˆªæ­¢æ—¥æœŸåœ¨å¤šå°‘å¤©å
                - days_before: æˆªæ­¢æ—¥æœŸåœ¨å¤šå°‘å¤©å‰

        Returns:
            ç­›é€‰åçš„ä¼šè®®åˆ—è¡¨
        """
        filtered = self.conferences

        # æŒ‰ç­‰çº§ç­›é€‰
        if 'rank' in filters:
            rank = filters['rank'].upper()
            if rank in ['A', 'B', 'C']:
                filtered = [c for c in filtered if c.get('rank') == rank]

        # æŒ‰é¢†åŸŸç­›é€‰
        if 'field' in filters:
            field = filters['field'].lower()
            filtered = [
                c for c in filtered
                if any(field in f.lower() for f in c.get('fields', []))
            ]

        # æŒ‰ç±»å‹ç­›é€‰
        if 'type' in filters:
            conf_type = filters['type']
            filtered = [c for c in filtered if c.get('type', 'conference') == conf_type]

        # æŒ‰æˆªæ­¢æ—¥æœŸç­›é€‰
        if 'days_after' in filters or 'days_before' in filters:
            from datetime import datetime, timedelta

            today = datetime.now()
            filtered = [
                c for c in filtered
                if c.get('deadline')
            ]

            if 'days_after' in filters:
                days = filters['days_after']
                deadline_date = today + timedelta(days=days)
                filtered = [
                    c for c in filtered
                    if datetime.strptime(c['deadline'], '%Y-%m-%d') <= deadline_date
                ]

            if 'days_before' in filters:
                days = filters['days_before']
                deadline_date = today + timedelta(days=days)
                filtered = [
                    c for c in filtered
                    if datetime.strptime(c['deadline'], '%Y-%m-%d') >= deadline_date
                ]

        return filtered

    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        from datetime import datetime

        total = len(self.conferences)

        # æŒ‰ç­‰çº§ç»Ÿè®¡
        rank_stats = {'A': 0, 'B': 0, 'C': 0, 'N/A': 0}
        for conf in self.conferences:
            rank = conf.get('rank', 'N/A')
            if rank in rank_stats:
                rank_stats[rank] += 1

        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_stats = {'conference': 0, 'journal': 0, 'workshop': 0}
        for conf in self.conferences:
            conf_type = conf.get('type', 'conference')
            type_stats[conf_type] = type_stats.get(conf_type, 0) + 1

        # æŒ‰éªŒè¯çŠ¶æ€ç»Ÿè®¡
        verification_stats = {
            'verified': 0,
            'conflict': 0,
            'unverified': 0,
            'outdated': 0
        }
        for conf in self.conferences:
            status = conf.get('verification', {}).get('status', 'unverified')
            verification_stats[status] = verification_stats.get(status, 0) + 1

        # å³å°†æˆªæ­¢çš„ä¼šè®®ï¼ˆ30å¤©å†…ï¼‰
        upcoming_count = 0
        today = datetime.now()
        thirty_days_later = today + timedelta(days=30)

        for conf in self.conferences:
            if conf.get('deadline'):
                try:
                    deadline = datetime.strptime(conf['deadline'], '%Y-%m-%d')
                    if today <= deadline <= thirty_days_later:
                        upcoming_count += 1
                except ValueError:
                    continue

        return {
            'total': total,
            'by_rank': rank_stats,
            'by_type': type_stats,
            'by_verification': verification_stats,
            'upcoming_30days': upcoming_count,
            'last_updated': self.metadata.get('last_updated', 'Unknown')
        }

    def _generate_conf_id(self, conf: Dict) -> str:
        """ç”Ÿæˆä¼šè®®å”¯ä¸€ID

        Args:
            conf: ä¼šè®®æ•°æ®

        Returns:
            å”¯ä¸€ID
        """
        name = conf.get('name', '')
        deadline = conf.get('deadline', '')

        # æå–ç¼©å†™
        abbrev_match = re.search(r'\b([A-Z]{2,})\b', name)
        if abbrev_match:
            abbrev = abbrev_match.group(1).lower()
        else:
            first_word = name.split()[0].lower() if name else 'conf'
            abbrev = re.sub(r'[^a-z0-9]', '', first_word)[:10]

        # æå–å¹´ä»½
        year_match = re.search(r'\b(20\d{2})\b', name + ' ' + deadline)
        year = year_match.group(1) if year_match else '0000'

        return f"{abbrev}-{year}"

    def _create_backup(self) -> str:
        """åˆ›å»ºå¤‡ä»½æ–‡ä»¶

        Returns:
            å¤‡ä»½æ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_filename = f"conferences_backup_{timestamp}.json"
        backup_path = os.path.join(self.backup_dir, backup_filename)

        shutil.copy2(self.data_file, backup_path)
        print(f"ğŸ’¾ å¤‡ä»½å·²åˆ›å»º: {backup_path}")

        return backup_path

    def list_backups(self, limit: int = 10) -> List[str]:
        """åˆ—å‡ºå¤‡ä»½æ–‡ä»¶

        Args:
            limit: æœ€å¤šè¿”å›å¤šå°‘ä¸ªå¤‡ä»½

        Returns:
            å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not os.path.exists(self.backup_dir):
            return []

        backups = [
            os.path.join(self.backup_dir, f)
            for f in os.listdir(self.backup_dir)
            if f.startswith('conferences_backup_') and f.endswith('.json')
        ]

        # æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åº
        backups.sort(key=lambda x: os.path.getmtime(x), reverse=True)

        return backups[:limit]

    def restore_backup(self, backup_path: str) -> bool:
        """ä»å¤‡ä»½æ¢å¤

        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„

        Returns:
            æ˜¯å¦æ¢å¤æˆåŠŸ
        """
        try:
            if not os.path.exists(backup_path):
                print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
                return False

            # å…ˆå¤‡ä»½å½“å‰æ•°æ®
            self._create_backup()

            # æ¢å¤æ•°æ®
            shutil.copy2(backup_path, self.data_file)

            # é‡æ–°åŠ è½½æ•°æ®
            self.load_data()

            print(f"âœ… å·²ä»å¤‡ä»½æ¢å¤: {backup_path}")
            return True

        except Exception as e:
            print(f"âŒ æ¢å¤å¤‡ä»½å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='ä¼šè®®æ•°æ®ç®¡ç†å·¥å…·')
    parser.add_argument('--file', type=str, default='conferences.json',
                       help='ä¼šè®®æ•°æ®æ–‡ä»¶ (é»˜è®¤: conferences.json)')
    parser.add_argument('--stats', action='store_true',
                       help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--migrate', action='store_true',
                       help='è¿ç§»æ—§æ ¼å¼æ•°æ®åˆ°æ–°æ ¼å¼')
    parser.add_argument('--backup', action='store_true',
                       help='åˆ›å»ºå¤‡ä»½')
    parser.add_argument('--list-backups', action='store_true',
                       help='åˆ—å‡ºå¤‡ä»½æ–‡ä»¶')
    parser.add_argument('--restore', type=str,
                       help='ä»æŒ‡å®šå¤‡ä»½æ¢å¤')

    args = parser.parse_args()

    print("="*60)
    print("ğŸ—‚ï¸  ä¼šè®®æ•°æ®ç®¡ç†å·¥å…·")
    print("="*60)

    # åˆ›å»ºç®¡ç†å™¨
    manager = ConferenceManager(args.file)

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        stats = manager.get_statistics()
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»æ•°: {stats['total']}")
        print(f"   æŒ‰ç­‰çº§: A={stats['by_rank']['A']}, "
              f"B={stats['by_rank']['B']}, C={stats['by_rank']['C']}")
        print(f"   æŒ‰ç±»å‹: ä¼šè®®={stats['by_type']['conference']}, "
              f"æœŸåˆŠ={stats['by_type']['journal']}")
        print(f"   éªŒè¯çŠ¶æ€: å·²éªŒè¯={stats['by_verification']['verified']}, "
              f"æœ‰å†²çª={stats['by_verification']['conflict']}")
        print(f"   å³å°†æˆªæ­¢(30å¤©): {stats['upcoming_30days']}")
        print(f"   æœ€åæ›´æ–°: {stats['last_updated']}")

    # è¿ç§»æ•°æ®
    if args.migrate:
        print("\nğŸ”„ æ­£åœ¨è¿ç§»æ•°æ®...")
        manager.save_data(create_backup=True)
        print("âœ… æ•°æ®è¿ç§»å®Œæˆ")

    # åˆ›å»ºå¤‡ä»½
    if args.backup:
        print("\nğŸ’¾ æ­£åœ¨åˆ›å»ºå¤‡ä»½...")
        backup_path = manager._create_backup()
        print(f"âœ… å¤‡ä»½å·²åˆ›å»º: {backup_path}")

    # åˆ—å‡ºå¤‡ä»½
    if args.list_backups:
        print("\nğŸ“‹ å¤‡ä»½æ–‡ä»¶åˆ—è¡¨:")
        backups = manager.list_backups()
        if backups:
            for i, backup in enumerate(backups, 1):
                mtime = datetime.fromtimestamp(os.path.getmtime(backup))
                size = os.path.getsize(backup) / 1024  # KB
                print(f"   {i}. {os.path.basename(backup)}")
                print(f"      æ—¶é—´: {mtime.strftime('%Y-%m-%d %H:%M:%S')}, "
                      f"å¤§å°: {size:.1f} KB")
        else:
            print("   (æ— å¤‡ä»½æ–‡ä»¶)")

    # æ¢å¤å¤‡ä»½
    if args.restore:
        print(f"\nğŸ”„ æ­£åœ¨ä»å¤‡ä»½æ¢å¤: {args.restore}")
        manager.restore_backup(args.restore)

    print("="*60)


if __name__ == '__main__':
    main()
