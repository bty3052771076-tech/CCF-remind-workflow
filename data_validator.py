#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®éªŒè¯å™¨ - äº¤å‰éªŒè¯ä¼šè®®æ•°æ®å¹¶æ£€æµ‹å†²çª
æ”¯æŒå¤šæ•°æ®æºéªŒè¯ã€å†²çªæ£€æµ‹å’Œç½®ä¿¡åº¦è®¡ç®—
"""

import json
import re
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from difflib import SequenceMatcher
from enum import Enum

# Windowsæ§åˆ¶å°ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import codecs
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)


class ConflictType(Enum):
    """å†²çªç±»å‹æšä¸¾"""
    DEADLINE_MISMATCH = "deadline_mismatch"       # æˆªæ­¢æ—¥æœŸä¸ä¸€è‡´
    RANK_MISMATCH = "rank_mismatch"               # ç­‰çº§ä¸ä¸€è‡´
    MISSING_FIELD = "missing_field"               # å­—æ®µç¼ºå¤±
    DUPLICATE_ENTRY = "duplicate_entry"           # é‡å¤æ¡ç›®
    NAME_MISMATCH = "name_mismatch"               # åç§°ä¸åŒ¹é…


class VerificationStatus(Enum):
    """éªŒè¯çŠ¶æ€æšä¸¾"""
    VERIFIED = "verified"                         # å·²éªŒè¯
    CONFLICT = "conflict"                         # æœ‰å†²çª
    UNVERIFIED = "unverified"                     # æœªéªŒè¯
    OUTDATED = "outdated"                         # å·²è¿‡æœŸ


class ConflictResolver:
    """å†²çªè§£å†³å™¨"""

    @staticmethod
    def by_priority(sources: List[Dict], priority_order: List[str]) -> Dict:
        """æŒ‰ä¼˜å…ˆçº§è§£å†³å†²çª

        Args:
            sources: æ•°æ®æºåˆ—è¡¨
            priority_order: ä¼˜å…ˆçº§é¡ºåºï¼ˆä»é«˜åˆ°ä½ï¼‰

        Returns:
            ä¼˜å…ˆçº§æœ€é«˜çš„æ•°æ®æº
        """
        for priority_id in priority_order:
            for source in sources:
                if source.get('source_id') == priority_id:
                    return source
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¼˜å…ˆçº§åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ª
        return sources[0] if sources else {}

    @staticmethod
    def by_majority(sources: List[Dict], field: str) -> Tuple[any, int]:
        """æŒ‰å¤šæ•°æŠ•ç¥¨è§£å†³å†²çª

        Args:
            sources: æ•°æ®æºåˆ—è¡¨
            field: è¦æ¯”è¾ƒçš„å­—æ®µå

        Returns:
            (æœ€å¸¸è§çš„å€¼, å‡ºç°æ¬¡æ•°)
        """
        values = [s.get('data', {}).get(field) for s in sources if s.get('data', {}).get(field)]

        if not values:
            return None, 0

        # ç»Ÿè®¡æ¯ä¸ªå€¼çš„å‡ºç°æ¬¡æ•°
        value_counts = {}
        for value in values:
            value_counts[value] = value_counts.get(value, 0) + 1

        # æ‰¾åˆ°å‡ºç°æ¬¡æ•°æœ€å¤šçš„å€¼
        most_common = max(value_counts.items(), key=lambda x: x[1])
        return most_common

    @staticmethod
    def by_recency(sources: List[Dict]) -> Dict:
        """æŒ‰æ—¶é—´æˆ³è§£å†³å†²çªï¼ˆä½¿ç”¨æœ€æ–°çš„æ•°æ®ï¼‰

        Args:
            sources: æ•°æ®æºåˆ—è¡¨

        Returns:
            æ—¶é—´æˆ³æœ€æ–°çš„æ•°æ®æº
        """
        valid_sources = [s for s in sources if s.get('last_checked')]

        if not valid_sources:
            return sources[0] if sources else {}

        # æŒ‰æ—¶é—´æˆ³é™åºæ’åº
        sorted_sources = sorted(
            valid_sources,
            key=lambda x: x['last_checked'],
            reverse=True
        )

        return sorted_sources[0]


class DataValidator:
    """æ•°æ®éªŒè¯å™¨ - äº¤å‰éªŒè¯ä¼šè®®æ•°æ®"""

    # éªŒè¯è§„åˆ™é…ç½®
    VALIDATION_RULES = {
        'deadline': {
            'required': True,
            'min_sources': 1,
            'tolerance_days': 3,  # å…è®¸çš„æ—¥æœŸå·®å¼‚å¤©æ•°
        },
        'rank': {
            'required': True,
            'min_sources': 1,
            'valid_values': ['A', 'B', 'C', 'N/A'],
            'authoritative_sources': ['ccf_official', 'manual']
        },
        'name': {
            'required': True,
            'min_sources': 1,
            'similarity_threshold': 0.85  # åç§°ç›¸ä¼¼åº¦é˜ˆå€¼
        }
    }

    def __init__(self, sources_config: str = 'sources.json'):
        """åˆå§‹åŒ–æ•°æ®éªŒè¯å™¨

        Args:
            sources_config: æ•°æ®æºé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.sources = self._load_sources(sources_config)
        self.resolver = ConflictResolver()

    def _load_sources(self, sources_file: str) -> List[Dict]:
        """åŠ è½½æ•°æ®æºé…ç½®"""
        try:
            with open(sources_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('sources', [])
        except (FileNotFoundError, json.JSONDecodeError):
            return []

    def validate_all(self, multi_source_data: Dict[str, List[Dict]]) -> Dict:
        """éªŒè¯æ‰€æœ‰ä¼šè®®æ•°æ®

        Args:
            multi_source_data: {source_id: conferences_list} æ ¼å¼çš„æ•°æ®

        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        print(f"ğŸ” å¼€å§‹éªŒè¯ {len(multi_source_data)} ä¸ªæ•°æ®æº...")

        # æŒ‰ä¼šè®®åç§°åˆ†ç»„
        grouped_conferences = self._group_by_name(multi_source_data)

        # éªŒè¯æ¯ä¸ªä¼šè®®ç»„
        results = {
            'total': len(grouped_conferences),
            'verified': [],
            'conflicts': [],
            'unverified': [],
            'statistics': {}
        }

        for conf_key, conf_group in grouped_conferences.items():
            validation_result = self.validate_conference_group(conf_key, conf_group)

            if validation_result['status'] == VerificationStatus.VERIFIED:
                results['verified'].append(validation_result)
            elif validation_result['status'] == VerificationStatus.CONFLICT:
                results['conflicts'].append(validation_result)
            else:
                results['unverified'].append(validation_result)

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        results['statistics'] = self._calculate_statistics(results)

        # æ‰“å°æ‘˜è¦
        self._print_validation_summary(results)

        return results

    def validate_conference_group(self, conf_key: str, conf_group: List[Dict]) -> Dict:
        """éªŒè¯ä¸€ç»„åŒåä¼šè®®

        Args:
            conf_key: ä¼šè®®é”®ï¼ˆåç§°ï¼‰
            conf_group: åŒåä¼šè®®çš„æ•°æ®åˆ—è¡¨

        Returns:
            éªŒè¯ç»“æœ
        """
        sources = []
        conflicts = []

        # æ”¶é›†æ‰€æœ‰æ•°æ®æºçš„ä¿¡æ¯
        for conf in conf_group:
            source_id = conf.get('source_id', 'unknown')
            sources.append({
                'source_id': source_id,
                'data': {
                    'name': conf.get('name'),
                    'deadline': conf.get('deadline'),
                    'rank': conf.get('rank'),
                    'website': conf.get('website'),
                    'conference_date': conf.get('conference_date')
                },
                'last_checked': datetime.now().strftime('%Y-%m-%d'),
                'priority': self._get_source_priority(source_id)
            })

        # æ£€æµ‹å†²çª
        if len(sources) >= 2:
            # æ£€æŸ¥æˆªæ­¢æ—¥æœŸå†²çª
            deadline_conflict = self._check_deadline_conflict(sources)
            if deadline_conflict:
                conflicts.append(deadline_conflict)

            # æ£€æŸ¥ç­‰çº§å†²çª
            rank_conflict = self._check_rank_conflict(sources)
            if rank_conflict:
                conflicts.append(rank_conflict)

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(sources, conflicts)

        # ç¡®å®šéªŒè¯çŠ¶æ€
        if conflicts:
            status = VerificationStatus.CONFLICT
        elif confidence >= 0.8 and len(sources) >= 2:
            status = VerificationStatus.VERIFIED
        elif len(sources) >= 1:
            status = VerificationStatus.UNVERIFIED
        else:
            status = VerificationStatus.OUTDATED

        return {
            'key': conf_key,
            'name': conf_group[0].get('name', conf_key),
            'status': status.value,
            'sources': sources,
            'conflicts': conflicts,
            'confidence': confidence,
            'recommended_data': self._get_recommended_data(sources, conflicts)
        }

    def _group_by_name(self, multi_source_data: Dict[str, List[Dict]]) -> Dict[str, List[Dict]]:
        """æŒ‰ä¼šè®®åç§°åˆ†ç»„

        Args:
            multi_source_data: å¤šæºä¼šè®®æ•°æ®

        Returns:
            {conf_key: [conf_list]} çš„å­—å…¸
        """
        grouped = {}

        for source_id, conferences in multi_source_data.items():
            for conf in conferences:
                # ç”Ÿæˆæ ‡å‡†åŒ–é”®
                conf_key = self._generate_conf_key(conf.get('name', ''))

                if conf_key not in grouped:
                    grouped[conf_key] = []

                # æ·»åŠ æ•°æ®æºID
                conf['source_id'] = source_id
                grouped[conf_key].append(conf)

        return grouped

    def _generate_conf_key(self, name: str) -> str:
        """ç”Ÿæˆä¼šè®®é”®ï¼ˆç”¨äºåˆ†ç»„ï¼‰

        Args:
            name: ä¼šè®®åç§°

        Returns:
            æ ‡å‡†åŒ–çš„ä¼šè®®é”®
        """
        # ç§»é™¤å¹´ä»½å’Œç‰¹æ®Šå­—ç¬¦
        key = re.sub(r'\b20\d{2}\b', '', name)  # ç§»é™¤å¹´ä»½
        key = re.sub(r'[^a-zA-Z0-9]', '', key)  # åªä¿ç•™å­—æ¯æ•°å­—
        key = key.lower().strip()

        return key

    def _check_deadline_conflict(self, sources: List[Dict]) -> Optional[Dict]:
        """æ£€æŸ¥æˆªæ­¢æ—¥æœŸå†²çª

        Args:
            sources: æ•°æ®æºåˆ—è¡¨

        Returns:
            å†²çªä¿¡æ¯ï¼ˆå¦‚æœæ²¡æœ‰å†²çªè¿”å›Noneï¼‰
        """
        deadlines = []
        for source in sources:
            deadline = source.get('data', {}).get('deadline')
            if deadline:
                try:
                    deadline_date = datetime.strptime(deadline, '%Y-%m-%d')
                    deadlines.append((deadline, deadline_date, source['source_id']))
                except ValueError:
                    continue

        if len(deadlines) < 2:
            return None

        # æ£€æŸ¥æ—¥æœŸå·®å¼‚
        deadline_dates = [d[1] for d in deadlines]
        min_date = min(deadline_dates)
        max_date = max(deadline_dates)
        days_diff = (max_date - min_date).days

        tolerance = self.VALIDATION_RULES['deadline']['tolerance_days']

        if days_diff > tolerance:
            return {
                'type': ConflictType.DEADLINE_MISMATCH.value,
                'field': 'deadline',
                'values': [d[0] for d in deadlines],
                'sources': [d[2] for d in deadlines],
                'days_difference': days_diff,
                'severity': 'high' if days_diff > 7 else 'medium'
            }

        return None

    def _check_rank_conflict(self, sources: List[Dict]) -> Optional[Dict]:
        """æ£€æŸ¥ç­‰çº§å†²çª

        Args:
            sources: æ•°æ®æºåˆ—è¡¨

        Returns:
            å†²çªä¿¡æ¯ï¼ˆå¦‚æœæ²¡æœ‰å†²çªè¿”å›Noneï¼‰
        """
        ranks = []
        for source in sources:
            rank = source.get('data', {}).get('rank')
            if rank and rank != 'N/A':
                ranks.append((rank, source['source_id']))

        if len(set(r[0] for r in ranks)) > 1:
            return {
                'type': ConflictType.RANK_MISMATCH.value,
                'field': 'rank',
                'values': [r[0] for r in ranks],
                'sources': [r[1] for r in ranks],
                'severity': 'medium'
            }

        return None

    def _calculate_confidence(self, sources: List[Dict], conflicts: List[Dict]) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°

        Args:
            sources: æ•°æ®æºåˆ—è¡¨
            conflicts: å†²çªåˆ—è¡¨

        Returns:
            ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
        """
        if not sources:
            return 0.0

        # åŸºç¡€åˆ†æ•°ï¼šæ•°æ®æºæ•°é‡
        source_score = min(len(sources) * 0.3, 0.6)  # æœ€å¤š0.6åˆ†

        # æƒå¨æºåŠ åˆ†
        authoritative_count = sum(
            1 for s in sources
            if s['source_id'] in self.VALIDATION_RULES['rank']['authoritative_sources']
        )
        authority_score = min(authoritative_count * 0.2, 0.2)

        # å†²çªæ‰£åˆ†
        conflict_penalty = min(len(conflicts) * 0.3, 0.6)

        # ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆä¼˜å…ˆçº§é«˜çš„æ•°æ®æºæƒé‡æ›´é«˜ï¼‰
        priority_score = 0
        if sources:
            avg_priority = sum(s.get('priority', 999) for s in sources) / len(sources)
            priority_score = max(0, (10 - avg_priority) / 50)  # è½¬æ¢ä¸º0-0.2çš„åˆ†æ•°

        confidence = source_score + authority_score + priority_score - conflict_penalty

        return max(0.0, min(1.0, confidence))

    def _get_recommended_data(self, sources: List[Dict], conflicts: List[Dict]) -> Dict:
        """è·å–æ¨èçš„ä¼šè®®æ•°æ®ï¼ˆè§£å†³å†²çªåï¼‰

        Args:
            sources: æ•°æ®æºåˆ—è¡¨
            conflicts: å†²çªåˆ—è¡¨

        Returns:
            æ¨èçš„ä¼šè®®æ•°æ®
        """
        if not sources:
            return {}

        # å¦‚æœæœ‰å†²çªï¼Œä½¿ç”¨è§£å†³ç­–ç•¥
        if conflicts:
            # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©
            best_source = self.resolver.by_priority(
                sources,
                self.VALIDATION_RULES['rank']['authoritative_sources']
            )
            return best_source.get('data', {})

        # å¦‚æœæ²¡æœ‰å†²çªï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®æº
        return sources[0].get('data', {})

    def _get_source_priority(self, source_id: str) -> int:
        """è·å–æ•°æ®æºä¼˜å…ˆçº§

        Args:
            source_id: æ•°æ®æºID

        Returns:
            ä¼˜å…ˆçº§æ•°å€¼ï¼ˆè¶Šå°è¶Šé«˜ï¼‰
        """
        for source in self.sources:
            if source['id'] == source_id:
                return source.get('priority', 999)
        return 999

    def _calculate_statistics(self, results: Dict) -> Dict:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯

        Args:
            results: éªŒè¯ç»“æœ

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total = results['total']
        verified = len(results['verified'])
        conflicts = len(results['conflicts'])
        unverified = len(results['unverified'])

        return {
            'total_conferences': total,
            'verified_count': verified,
            'conflict_count': conflicts,
            'unverified_count': unverified,
            'verification_rate': f"{(verified / total * 100):.1f}%" if total > 0 else "0%",
            'conflict_rate': f"{(conflicts / total * 100):.1f}%" if total > 0 else "0%",
            'average_confidence': self._calculate_average_confidence(results)
        }

    def _calculate_average_confidence(self, results: Dict) -> float:
        """è®¡ç®—å¹³å‡ç½®ä¿¡åº¦

        Args:
            results: éªŒè¯ç»“æœ

        Returns:
            å¹³å‡ç½®ä¿¡åº¦
        """
        all_results = (
            results['verified'] +
            results['conflicts'] +
            results['unverified']
        )

        if not all_results:
            return 0.0

        total_confidence = sum(r.get('confidence', 0) for r in all_results)
        return total_confidence / len(all_results)

    def _print_validation_summary(self, results: Dict):
        """æ‰“å°éªŒè¯æ‘˜è¦

        Args:
            results: éªŒè¯ç»“æœ
        """
        stats = results['statistics']

        print(f"\n{'='*60}")
        print("ğŸ“Š éªŒè¯ç»“æœæ‘˜è¦")
        print(f"{'='*60}")
        print(f"æ€»ä¼šè®®æ•°: {stats['total_conferences']}")
        print(f"âœ… å·²éªŒè¯: {stats['verified_count']} ({stats['verification_rate']})")
        print(f"âš ï¸  æœ‰å†²çª: {stats['conflict_count']} ({stats['conflict_rate']})")
        print(f"â“ æœªéªŒè¯: {stats['unverified_count']}")
        print(f"ğŸ“ˆ å¹³å‡ç½®ä¿¡åº¦: {stats['average_confidence']:.2f}")
        print(f"{'='*60}")

    def save_report(self, results: Dict, filename: str):
        """ä¿å­˜éªŒè¯æŠ¥å‘Š

        Args:
            results: éªŒè¯ç»“æœ
            filename: æŠ¥å‘Šæ–‡ä»¶å
        """
        report = {
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'statistics': results['statistics'],
            'verified': results['verified'],
            'conflicts': results['conflicts'],
            'unverified': results['unverified']
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")

    def auto_fix_conflicts(self, conflicts: List[Dict], conferences: List[Dict]) -> int:
        """è‡ªåŠ¨ä¿®å¤å†²çªï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

        Args:
            conflicts: å†²çªåˆ—è¡¨
            conferences: ä¼šè®®æ•°æ®åˆ—è¡¨

        Returns:
            ä¿®å¤çš„å†²çªæ•°é‡
        """
        fixed_count = 0

        for conflict in conflicts:
            if conflict.get('conflicts'):
                # å¯¹äºæ¯ä¸ªå†²çªï¼Œä½¿ç”¨ä¼˜å…ˆçº§æœ€é«˜çš„æ•°æ®æº
                recommended = conflict.get('recommended_data', {})
                if recommended:
                    # æ›´æ–°ä¼šè®®æ•°æ®
                    conf_key = conflict.get('key')
                    for conf in conferences:
                        if self._generate_conf_key(conf.get('name', '')) == conf_key:
                            # æ›´æ–°å­—æ®µ
                            for field, value in recommended.items():
                                if value:  # åªæ›´æ–°éç©ºå€¼
                                    conf[field] = value
                            fixed_count += 1
                            break

        return fixed_count


def match_conference_name(name1: str, name2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªä¼šè®®åç§°çš„ç›¸ä¼¼åº¦

    Args:
        name1: ç¬¬ä¸€ä¸ªä¼šè®®åç§°
        name2: ç¬¬äºŒä¸ªä¼šè®®åç§°

    Returns:
        ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
    """
    # æ ‡å‡†åŒ–åç§°
    def normalize(name: str) -> str:
        # ç§»é™¤å¹´ä»½
        name = re.sub(r'\b20\d{2}\b', '', name)
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯æ•°å­—
        name = re.sub(r'[^a-zA-Z0-9]', '', name)
        # ç»Ÿä¸€å¤§å°å†™
        name = name.lower().strip()
        return name

    norm1, norm2 = normalize(name1), normalize(name2)

    # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
    return SequenceMatcher(None, norm1, norm2).ratio()


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='ä¼šè®®æ•°æ®éªŒè¯å·¥å…·')
    parser.add_argument('--data', type=str, required=True,
                       help='å¤šæºæ•°æ®æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰')
    parser.add_argument('--sources', type=str, default='sources.json',
                       help='æ•°æ®æºé…ç½®æ–‡ä»¶ (é»˜è®¤: sources.json)')
    parser.add_argument('--report', type=str,
                       help='ä¿å­˜éªŒè¯æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--verbose', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')

    args = parser.parse_args()

    print("="*60)
    print("ğŸ” ä¼šè®®æ•°æ®éªŒè¯å·¥å…·")
    print("="*60)

    # åŠ è½½æ•°æ®
    try:
        with open(args.data, 'r', encoding='utf-8') as f:
            multi_source_data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
        return 1
    except json.JSONDecodeError as e:
        print(f"âŒ æ•°æ®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return 1

    # åˆ›å»ºéªŒè¯å™¨
    validator = DataValidator(args.sources)

    # æ‰§è¡ŒéªŒè¯
    results = validator.validate_all(multi_source_data)

    # æ˜¾ç¤ºè¯¦ç»†å†²çªä¿¡æ¯
    if args.verbose and results['conflicts']:
        print(f"\nâš ï¸  å‘ç° {len(results['conflicts'])} ä¸ªå†²çª:")
        for i, conflict in enumerate(results['conflicts'][:10], 1):
            print(f"\n{i}. {conflict['name']}")
            for conf in conflict['conflicts']:
                print(f"   - {conf['type']}: {conf.get('values', [])}")

    # ä¿å­˜æŠ¥å‘Š
    if args.report:
        validator.save_report(results, args.report)

    print("="*60)
    return 0


if __name__ == '__main__':
    sys.exit(main())
