#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ›´æ–°å·¥å…·
è‡ªåŠ¨ä»å¤šä¸ªæ•°æ®æºè·å–ä¼šè®®æ•°æ®å¹¶æ›´æ–°åˆ°æœ¬åœ°æ•°æ®åº“
"""

import json
import sys
import argparse
from datetime import datetime
from typing import List, Dict

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from data_fetcher import DataFetcher
from data_validator import DataValidator
from conference_manager import ConferenceManager

# Windowsæ§åˆ¶å°ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import codecs
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)


class DataUpdater:
    """æ•°æ®æ›´æ–°å™¨"""

    def __init__(self, sources_file: str = 'sources.json'):
        """åˆå§‹åŒ–æ•°æ®æ›´æ–°å™¨

        Args:
            sources_file: æ•°æ®æºé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.fetcher = DataFetcher(sources_file)
        self.validator = DataValidator(sources_file)
        self.manager = ConferenceManager()

    def fetch_all_sources(self, source_ids: List[str] = None) -> Dict[str, List[Dict]]:
        """ä»æ‰€æœ‰æ•°æ®æºæŠ“å–æ•°æ®

        Args:
            source_ids: æŒ‡å®šè¦æŠ“å–çš„æ•°æ®æºIDåˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰

        Returns:
            æŒ‰æ•°æ®æºIDåˆ†ç»„çš„ä¼šè®®æ•°æ®å­—å…¸
        """
        print("ğŸŒ å¼€å§‹æŠ“å–æ•°æ®...")

        if source_ids:
            print(f"ğŸ“Œ æŒ‡å®šæ•°æ®æº: {', '.join(source_ids)}")
            sources = [s for s in self.fetcher.sources if s['id'] in source_ids]
        else:
            print("ğŸ“Œ ä½¿ç”¨æ‰€æœ‰å·²å¯ç”¨çš„æ•°æ®æº")
            sources = [s for s in self.fetcher.sources if s.get('enabled', True)]

        if not sources:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®æº")
            return {}

        all_data = {}
        for source in sources:
            source_id = source['id']
            source_name = source['name']

            print(f"\nğŸ“¥ æ­£åœ¨æŠ“å–: {source_name} ({source_id})...")
            try:
                data = self.fetcher.fetch_from_source(source_id)
                all_data[source_id] = data
                print(f"   âœ… æˆåŠŸè·å– {len(data)} ä¸ªä¼šè®®/æœŸåˆŠ")
            except Exception as e:
                print(f"   âŒ æŠ“å–å¤±è´¥: {e}")
                all_data[source_id] = []

        return all_data

    def validate_data(self, all_data: Dict[str, List[Dict]]) -> Dict:
        """éªŒè¯æŠ“å–çš„æ•°æ®

        Args:
            all_data: æŒ‰æ•°æ®æºåˆ†ç»„çš„ä¼šè®®æ•°æ®

        Returns:
            éªŒè¯æŠ¥å‘Š
        """
        print("\nğŸ” å¼€å§‹æ•°æ®éªŒè¯...")

        # åˆå¹¶æ‰€æœ‰æ•°æ®æº
        all_conferences = []
        for source_id, data in all_data.items():
            all_conferences.extend(data)

        print(f"ğŸ“Š æ€»å…± {len(all_conferences)} æ¡æ•°æ®å¾…éªŒè¯")

        # åˆ†ç»„éªŒè¯ï¼ˆæŒ‰ä¼šè®®åç§°ç›¸ä¼¼åº¦åˆ†ç»„ï¼‰
        validation_results = {}
        processed = set()

        for conf in all_conferences:
            conf_key = conf.get('name', '')
            if not conf_key or conf_key in processed:
                continue

            # æŸ¥æ‰¾ç›¸ä¼¼ä¼šè®®
            similar_confs = [c for c in all_conferences
                           if self.validator._name_similarity(conf_key, c.get('name', '')) > 0.85]

            if similar_confs:
                result = self.validator.validate_conference_group(conf_key, similar_confs)
                validation_results[conf_key] = result
                processed.add(conf_key)

        print(f"âœ… éªŒè¯å®Œæˆï¼Œå…± {len(validation_results)} ä¸ªä¼šè®®ç»„")

        # ç»Ÿè®¡
        verified = sum(1 for r in validation_results.values() if r['status'] == 'verified')
        conflicts = sum(1 for r in validation_results.values() if r['conflicts'])
        print(f"   - å·²éªŒè¯: {verified}")
        print(f"   - æœ‰å†²çª: {conflicts}")
        print(f"   - éœ€äººå·¥å®¡æ ¸: {len(validation_results) - verified}")

        return validation_results

    def merge_with_existing(self, all_data: Dict[str, List[Dict]],
                           validation_results: Dict = None,
                           auto_fix: bool = False) -> List[Dict]:
        """åˆå¹¶æŠ“å–çš„æ•°æ®åˆ°ç°æœ‰æ•°æ®åº“

        Args:
            all_data: æŠ“å–çš„æ•°æ®
            validation_results: éªŒè¯ç»“æœï¼ˆå¯é€‰ï¼‰
            auto_fix: æ˜¯å¦è‡ªåŠ¨ä¿®å¤å†²çª

        Returns:
            åˆå¹¶åçš„ä¼šè®®åˆ—è¡¨
        """
        print("\nğŸ”§ å¼€å§‹åˆå¹¶æ•°æ®...")

        # åŠ è½½ç°æœ‰æ•°æ®
        existing_confs = self.manager.conferences
        print(f"ğŸ“š ç°æœ‰ä¼šè®®æ•°: {len(existing_confs)}")

        # åˆå¹¶æ‰€æœ‰æ–°æ•°æ®
        new_confs = []
        for source_id, data in all_data.items():
            new_confs.extend(data)

        new_confs = self.fetcher.deduplicate_conferences(new_confs)
        print(f"ğŸ“ æ–°ä¼šè®®æ•°: {len(new_confs)}")

        # æ£€æŸ¥å·²å­˜åœ¨çš„ä¼šè®®
        existing_names = {c.get('name', ''): c for c in existing_confs}
        merged = existing_confs.copy()
        added_count = 0
        updated_count = 0

        for new_conf in new_confs:
            name = new_conf.get('name', '')
            if not name:
                continue

            if name in existing_names:
                # æ›´æ–°ç°æœ‰ä¼šè®®
                existing = existing_names[name]
                changed = False

                # æ›´æ–°æˆªæ­¢æ—¥æœŸï¼ˆå¦‚æœéªŒè¯ç»“æœå­˜åœ¨ä¸”æœ‰æ¨èå€¼ï¼‰
                if validation_results and name in validation_results:
                    result = validation_results[name]
                    if result.get('recommended_data'):
                        rec = result['recommended_data']
                        if 'deadline' in rec and rec['deadline'] != existing.get('deadline'):
                            existing['deadline'] = rec['deadline']
                            changed = True

                # æ›´æ–°å…¶ä»–å­—æ®µ
                for key in ['deadline', 'conference_date', 'website', 'description']:
                    if new_conf.get(key) and new_conf[key] != existing.get(key):
                        existing[key] = new_conf[key]
                        changed = True

                if changed:
                    updated_count += 1
            else:
                # æ·»åŠ æ–°ä¼šè®®
                merged.append(new_conf)
                added_count += 1

        print(f"   âœ… æ·»åŠ  {added_count} ä¸ªæ–°ä¼šè®®")
        print(f"   ğŸ”„ æ›´æ–° {updated_count} ä¸ªç°æœ‰ä¼šè®®")
        print(f"   ğŸ“Š æ€»è®¡ {len(merged)} ä¸ªä¼šè®®")

        return merged

    def save_report(self, report: Dict, filename: str = None):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report: æŠ¥å‘Šæ•°æ®
            filename: æ–‡ä»¶åï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'validation_report_{timestamp}.json'

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {filename}")

    def run(self, source_ids: List[str] = None,
            validate_only: bool = False,
            auto_fix: bool = False,
            save_report: bool = False,
            apply_changes: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´æ›´æ–°æµç¨‹

        Args:
            source_ids: æŒ‡å®šæ•°æ®æº
            validate_only: ä»…éªŒè¯ä¸åº”ç”¨æ›´æ”¹
            auto_fix: è‡ªåŠ¨ä¿®å¤å†²çª
            save_report: ä¿å­˜éªŒè¯æŠ¥å‘Š
            apply_changes: åº”ç”¨æ›´æ”¹åˆ°æ•°æ®æ–‡ä»¶

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. æŠ“å–æ•°æ®
            all_data = self.fetch_all_sources(source_ids)
            if not all_data:
                return False

            total_fetched = sum(len(data) for data in all_data.values())
            if total_fetched == 0:
                print("âš ï¸  æ²¡æœ‰æŠ“å–åˆ°ä»»ä½•æ•°æ®")
                return False

            # 2. éªŒè¯æ•°æ®
            validation_results = self.validate_data(all_data)

            # 3. ä¿å­˜æŠ¥å‘Š
            if save_report:
                report = {
                    'timestamp': datetime.now().isoformat(),
                    'sources': list(all_data.keys()),
                    'total_fetched': total_fetched,
                    'validation_results': validation_results
                }
                self.save_report(report)

            # 4. å¦‚æœåªæ˜¯éªŒè¯ï¼Œåˆ°æ­¤ç»“æŸ
            if validate_only:
                print("\nâœ… éªŒè¯å®Œæˆï¼ˆæœªåº”ç”¨æ›´æ”¹ï¼‰")
                return True

            # 5. åˆå¹¶æ•°æ®
            merged = self.merge_with_existing(all_data, validation_results, auto_fix)

            # 6. åº”ç”¨æ›´æ”¹
            if apply_changes:
                print("\nğŸ’¾ æ­£åœ¨ä¿å­˜æ›´æ”¹...")
                self.manager.conferences = merged
                self.manager.save_data()
                print("âœ… æ•°æ®å·²æ›´æ–°åˆ° conferences.json")
            else:
                print("\nâš ï¸  æœªåº”ç”¨æ›´æ”¹ï¼ˆä½¿ç”¨ --apply ä¿å­˜åˆ°æ–‡ä»¶ï¼‰")

            return True

        except Exception as e:
            print(f"âŒ æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='CCFä¼šè®®æ•°æ®æ›´æ–°å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä»æ‰€æœ‰æ•°æ®æºæŠ“å–å¹¶éªŒè¯
  python update_data.py

  # åªéªŒè¯ä¸åº”ç”¨æ›´æ”¹
  python update_data.py --validate-only

  # ä»ç‰¹å®šæ•°æ®æºæŠ“å–
  python update_data.py --sources ccfddl

  # è‡ªåŠ¨ä¿®å¤å¹¶åº”ç”¨æ›´æ”¹
  python update_data.py --auto-fix --apply

  # ä¿å­˜éªŒè¯æŠ¥å‘Š
  python update_data.py --save-report
                                    """
    )
    parser.add_argument('-s', '--sources', type=str, nargs='+',
                        help='æŒ‡å®šæ•°æ®æºï¼ˆå¦‚ï¼šccfddl manualï¼‰')
    parser.add_argument('--validate-only', action='store_true',
                        help='ä»…éªŒè¯æ•°æ®ï¼Œä¸åº”ç”¨æ›´æ”¹')
    parser.add_argument('--auto-fix', action='store_true',
                        help='è‡ªåŠ¨ä¿®å¤å†²çª')
    parser.add_argument('--save-report', action='store_true',
                        help='ä¿å­˜éªŒè¯æŠ¥å‘Šåˆ°æ–‡ä»¶')
    parser.add_argument('--apply', action='store_true',
                        help='åº”ç”¨æ›´æ”¹åˆ°conferences.json')

    args = parser.parse_args()

    try:
        updater = DataUpdater()
        success = updater.run(
            source_ids=args.sources,
            validate_only=args.validate_only,
            auto_fix=args.auto_fix,
            save_report=args.save_report,
            apply_changes=args.apply
        )
        return 0 if success else 1
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
